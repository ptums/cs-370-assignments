{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'np_utils' from 'keras.utils' (/Users/petertumulty/.pyenv/versions/3.9.12/lib/python3.9/site-packages/keras/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cifar10\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m np_utils\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, Activation, Flatten\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'np_utils' from 'keras.utils' (/Users/petertumulty/.pyenv/versions/3.9.12/lib/python3.9/site-packages/keras/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# CIFAR_10 is a set of 60k images 32x32 pixels on 3 channels\n",
    "# Sets the number of color channels in the input images.\n",
    "# 3 is for RGB\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# sets width to 32px\n",
    "IMG_ROWS = 32\n",
    "\n",
    "# set the height to 32px\n",
    "IMG_COLS = 32\n",
    "\n",
    "#constant\n",
    "\n",
    "# is the number of samples that will be propagated\n",
    "# through the neural network at once.\n",
    "BATCH_SIZE = 128\n",
    "# number of rounds the data will be passed \n",
    "# through the neural network\n",
    "NB_EPOCH = 20\n",
    "# Classes or categories tthe input data can be\n",
    "# classified into.\n",
    "NB_CLASSES = 10\n",
    "# Controls the amount of information printed\n",
    "# during the training process. -- cool but not necessary -- \n",
    "VERBOSE = 1\n",
    "# This line sets the fraction of the training data\n",
    "# that will be used for validation during training.\n",
    "#  In this case, 20% of the training\n",
    "# data will be used for validation.\n",
    "VALIDATION_SPLIT = 0.2\n",
    "# the optimizer algorithm is RMSprop\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "\n",
    "\n",
    "#load dataset\n",
    "\n",
    "# mapping the elements of the image data to x values with labels\n",
    "# and y values with labels\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "# Convert the class labels from integers to one-hot\n",
    "# encoded vectors.\n",
    "# first index points the item the second index points to some other\n",
    "# posiont \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "## Converts the results to float32 integers (floating-point numbers)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# does some weird division by 255\n",
    "# Normalize them by dividing by 255 (the maximum pixel value).\n",
    "#  This is a common preprocessing step for image data\n",
    "# as it helps improve the numerical stability and\n",
    "# convergence of the neural network. -- SO MANY QUESTIONS !!! ---\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# network\n",
    "# initializes the model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer One\n",
    "# This is the first convolutional layer with 32 filters of size 3x3\n",
    "# The padding is set to 'same' to ensure that the output has the same spatial dimensions as the input\n",
    "# The input shape is specified as (IMG_ROWS, IMG_COLS, IMG_CHANNELS)\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "\n",
    "# Activation function for the first convolutional layer (ReLU)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Second convolutional layer with 32 filters of size 3x3\n",
    "# The padding is set to 'same' to ensure that the output has the same spatial dimensions as the input\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same'))\n",
    "\n",
    "# Activation function for the second convolutional layer (ReLU)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Max pooling layer with a 2x2 pool size\n",
    "# This downsamples the feature maps and introduces translation invariance -- explain...\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with a rate of 0.25 (25% of the inputs will be randomly set to 0)\n",
    "# Dropout is a regularization technique to prevent overfitting -- explain...\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# End of Layer One\n",
    "\n",
    "# Layer Two\n",
    "# Third convolutional layer with 64 filters of size 3x3\n",
    "# The padding is set to 'same' to ensure that the output has the same spatial dimensions as the input\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "\n",
    "# Activation function for the third convolutional layer (ReLU)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Fourth convolutional layer with 64 filters of size 3x3\n",
    "# No padding specified, so the output spatial dimensions may be reduced\n",
    "model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "\n",
    "# Activation function for the fourth convolutional layer (ReLU)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# cleanup\n",
    "\n",
    "# Cleanup/Pooling Layer\n",
    "# Max pooling layer with a 2x2 pool size\n",
    "# This downsamples the feature maps and introduces translation invariance\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout layer with a rate of 0.25 (25% of the inputs will be randomly set to 0)\n",
    "# Dropout is a regularization technique to prevent overfitting -- dont work too hard \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten Layer\n",
    "# Flattens the multi-dimensional output from the convolutional and pooling layers\n",
    "# into a 1D vector, which is required for the fully connected layers -- thats cray\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "# Fully connected layer with 512 units\n",
    "# This layer combines and processes the features learned by the convolutional and pooling layers\n",
    "model.add(Dense(512))\n",
    "\n",
    "# Activation function for the fully connected layer (ReLU)\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Dropout layer with a rate of 0.5 (50% of the inputs will be randomly set to 0)\n",
    "# Dropout is a regularization technique to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output Layer\n",
    "# Fully connected layer with the same number of units as the number of classes (NB_CLASSES)\n",
    "# This is the final layer that produces the output predictions\n",
    "model.add(Dense(NB_CLASSES))\n",
    "\n",
    "# Softmax activation function for the output layer\n",
    "# Softmax is commonly used in multi-class classification problems\n",
    "# It outputs a probability distribution over the classes, where the sum of probabilities is 1\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# results\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM,\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test,\n",
    "batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can training machines on images be harmful? What are the negative impacts of the technology on our society*\n",
    "\n",
    "Training machines on images can be harmful because they inherently introduce bias by design. Beyond training the DCNN on biased data, the pooling layer, specifically the max pooling layer, starts a process that is inherently biased. I came to this conclusion after reviewing the code from Chapter 3 of \"Deep Learning with Keras\". To my understanding, max pooling is introduced into the script, designed to prioritize some features of the element over others. This process corrupts the input data in some way. For example, it can make the data insensitive to small shifts, which can result in biased data. \"In Max Pooling, small changes in the non-maximal values will be ignored. This insensitivity to small changes can be problematic and can bias the results (Arham, 2023).\" When we introduce favoritism into the training data at that core level of the DCNN, the output will always exhibit some degree of bias, regardless of the input. This change can emphasis the negative aspects of the input data unintentionally. \n",
    "\n",
    "\n",
    "## For example, could such an algorithm eventually be used to distinguish people’s faces? If so, what are the ethical and privacy implications?\n",
    "\n",
    "When passing image data to a neural network, it's important to consider the potential negative effects, particularly from an ethical standpoint. For instance, feeding images of people into a Deep Convolutional Neural Network (DCNN) prompts the algorithm to analyze and interpret these images. If the developers of the DCNN persistently refine the system to recreate images with high accuracy and likeness based on the input data, this can lead to significant ethical concerns. One problem based on this fact, which is also is becoming more prevalent in our society: deepfakes, which are \"kind of synthetic media where a person in an image or video is swapped with another person’s likeness (Dhiman, 2023).\" Even though the code we ran seemed pretty interesting at the time, it could easily be refactored to generate deepfake photos based on the training data provided, raising further a very important ethical concerns.\n",
    "\n",
    "There isn't much argument against how deepfakes are unethical and invade personal privacy. A recent example of the impact how damaging deepfakes can be is what happened to Taylor Swift. Taylor Swift was a victim of deepfake with her face imposed over pornographic images and shared on social media (Associated Press, 2024). As of right now the source of these images is unknown, but whoever is behind it they are clearly wrong morally and legally.  Since the incident according to the BBC, \"US politicians have called for new laws to criminalise the creation of deepfake(Rahman-Jones, 2024)\" based on this incident. This case highlights the urgent need for legislation that specifically targets deepfake technology to protect individuals' rights and privacy.\n",
    "\n",
    "**References:**\n",
    "\n",
    "Arham, M. (2023, September 28). Diving into the pool: Unraveling the magic of CNN pooling layers. KDnuggets. Retrieved from [https://www.kdnuggets.com/diving-into-the-pool-unraveling-the-magic-of-cnn-pooling-layers](https://www.kdnuggets.com/diving-into-the-pool-unraveling-the-magic-of-cnn-pooling-layers)\n",
    "\n",
    "Dhiman, B. (2023, December 7). Exploding AI-generated deepfakes and misinformation: A threat to global concern in the 21st century. ResearchGate. [https://www.researchgate.net/publication/376329868_Exploding_AI-Generated_Deepfakes_and_Misinformation_A_Threat_to_Global_Concern_in_the_21st_Century](https://www.researchgate.net/publication/376329868_Exploding_AI-Generated_Deepfakes_and_Misinformation_A_Threat_to_Global_Concern_in_the_21st_Century)\n",
    "\n",
    "Associated Press. (2024, January 26). Fans fight back as fake explicit images of Taylor Swift spread on social media. MSN. [https://www.msn.com/en-us/news/technology/fans-fight-back-as-fake-explicit-images-of-taylor-swift-spread-on-social-media/ar-BB1hjPDV](https://www.msn.com/en-us/news/technology/fans-fight-back-as-fake-explicit-images-of-taylor-swift-spread-on-social-media/ar-BB1hjPDV)\n",
    "\n",
    "Rahman-Jones, I. (2024, January 27). Taylor Swift deepfakes spark calls in Congress for new legislation. BBC News. [https://www.bbc.com/news/technology-68110476?embed=true](https://www.bbc.com/news/technology-68110476?embed=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
